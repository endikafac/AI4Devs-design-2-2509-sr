# PROMPT EFC-0
Tengo esta informaci√≥n de las historias de usuario que pongo adjunta. (La informaci√≥n copiada del master).
Tengo un PRD completo del sistema LTI ATS en LTI-EFC.md y necesitas crear prompts estructurados para generar User Stories, Backlog, Tickets y Estimaciones. Voy a actualizar el archivo prompts.md con todos los prompts necesarios usando la metodolog√≠a memory-bank.

Tengo que hacer este ejercicio, puedes ayudarme a preparar los promtps necesarios para que ejecute todo. Creame un fichero denominado prompt.md donde se a√±adan todos los prompts que hemos generado, incluido este. Y adem√°s, utilizando la metodolog√≠a de memori-bank, explica el contexto que queremos hacer, y prepararme los prompts que necesito para hacer el ejercicio que describo a continuaci√≥n.

En este ejercicio vas a actuar como un Product Manager y Business Analyst. 
Usando los documentos que generaste en la secci√≥n anterior y que conforman un PRD b√°sico (funcionalidades clave, casos de uso, modelo de datos...), tu misi√≥n es preparar la documentaci√≥n necesaria para empezar a implementar LTI:
1. Generar las User Stories. Puedes implementar tantas como quieras y puedas, el m√≠nimo son 2. Utiliza lo aprendido sobre buenas pr√°cticas de este cap√≠tulo para que contenga toda la informaci√≥n necesaria, y como consejo, usa una plantilla com√∫n para todas ellas (recuerda que dejamos un ejemplo de plantilla en la secci√≥n de User Stories).
2. Arma el Backlog de producto con las User Stories, prioriz√°ndolas como consideres conveniente acorde a alguna metodolog√≠a concreta. experimenta con diferentes formas de generar un prompt que te pueda genera tu back log basado en la documentaci√≥n que has generado previamente. Entrega los diferentes prompts que usaste e indica cual prompt te dio mejores resultados. Entrega junto a los prompts tus conclusiones, por qu√© crees este prompt fue efectivo. 
3. Elige la User Story que prefieras, y genera los Tickets de trabajo. Aterr√≠zalos t√©cnicamente, tal y como se hace en las reuniones de planificaci√≥n
4. (Extra üéÅ) Estima el esfuerzo de los tickets de trabajo usando la metodolog√≠a (fibonacci, poker, tallas de camiseta) y unidades (horas, puntos de historia) que prefieras.

1. Visi√≥n general de la gesti√≥n de producto
En el contexto de las metodolog√≠as √°giles, hay varios elementos a distintos niveles de abstracci√≥n que trabajan en conjunto para facilitar la planificaci√≥n y ejecuci√≥n efectiva de productos y proyectos. 

Product Roadmap
Es un plan estrat√©gico de alto nivel que define la visi√≥n y direcci√≥n del producto a lo largo del tiempo. El roadmap comunica los objetivos y las prioridades a largo plazo, y est√° dise√±ado para guiar la toma de decisiones estrat√©gicas en relaci√≥n con el desarrollo del producto.

√âpica
Una √©pica es una gran agrupaci√≥n de trabajo que se puede desglosar en historias de usuario m√°s peque√±as. Las √©picas son componentes clave del roadmap y representan iniciativas o caracter√≠sticas importantes que se desarrollar√°n.

Historia de Usuario
Las historias de usuario son descripciones cortas y simples de una caracter√≠stica desde la perspectiva del usuario final. Estas historias ayudan a que el equipo entienda lo que necesita el usuario y por qu√©. Las historias de usuario son desgloses de las √©picas y se dise√±an para ser entregadas en uno o varios sprints.

Ticket de Trabajo
Los tickets o tareas son a√∫n m√°s espec√≠ficos que las historias de usuario y a menudo representan acciones concretas que se deben realizar para completar una historia de usuario. Estos pueden incluir bugs a corregir, mejoras, o tareas espec√≠ficas de desarrollo y pruebas.






2. Introducci√≥n a las Historias de Usuario
Vamos a centrarnos ahora en el componente esencial de los flujos de trabajo en equipos de software √°giles: las historias de usuario. 

Ya se ha comentado que describen una caracter√≠sticas desde la perspectiva del valor aportado al usuario final. Sin embargo, a menudo se genera confusi√≥n entre las historias de usuario, los casos de uso y los tickets de trabajo. Los 3 nos ayudan a identificar ls funcionalidades que vamos a desarrollar, as√≠ como los requisitos, tanto funcionales como no funcionales, pero desde diferentes √≥pticas. ¬øC√≥mo se relacionan, y en qu√© se diferencian?

User Stories: Estas historias describen una funci√≥n del software desde la perspectiva del usuario final. A menudo se redactan en la forma "Como [rol de usuario], quiero [objetivo] para que pueda [beneficio]". Las User Stories pueden derivarse directamente de las funcionalidades o casos de uso identificadas en la fase de an√°lisis, y deben centrarse en satisfacer una necesidad del usuario final.
Use Cases: Los Use Cases son descripciones m√°s detalladas de c√≥mo un sistema debe comportarse y se utilizan para capturar las interacciones de usuario y sistema. A menudo proporcionan un paso a paso de c√≥mo un usuario interact√∫a con una funcionalidad para lograr un resultado y pueden incluir flujos de trabajo alternativos o "caminos felices" y "no tan felices". Los casos de uso pueden ser √∫tiles para describir tanto requisitos funcionales como no funcionales. M√°s informaci√≥n y ejemplos en el m√≥dulo anterior
Tickets de trabajo (a veces llamados "issues" o "historias" en JIRA y otras plataformas): Estos son los elementos de trabajo individuales que los desarrolladores deben completar. Estos tickets pueden representar User Stories o Use Cases, o pueden representar tareas t√©cnicas espec√≠ficas necesarias para implementar una funcionalidad (feature). Una feature puede desglosarse en varios tickets dependiendo de su complejidad.
As√≠ que, para resumir:

En el an√°lisis de requisitos y casos de uso se define la visi√≥n y los objetivos del producto, y se identifican las features necesarias para cumplirlo. 
Las features podr√≠an ser un User Story o un conjunto de User Stories que, una vez implementadas, cumplen con un Requisito Funcional. 
Cada User Story puede a su vez desglosarse en Tickets de trabajo que son las tareas espec√≠ficas que los desarrolladores deben llevar a cabo para implementar la feature. En estos tickets de trabajo se deben cubrir requisitos tanto funcionales como no funcionales (tales como tiempos de respuesta, seguridad, escalabilidad, mantenibilidad...).
Caracter√≠sticas de las User Stories
Las User Stories describen una caracter√≠stica del software desde la perspectiva del usuario final. 

Las caracter√≠sticas m√°s importantes que deben cumplir las User Stories para cumplir su cometido son:

Descripci√≥n informal y en lenguaje natural: Las User Stories describen las caracter√≠sticas del software de una manera sencilla y no t√©cnica, desde el punto de vista del usuario. Es importante el storytelling, no es una descripci√≥n t√©cnica, y si se puede vincular al avatar / buyer persona / usuario que lo demanda, mejor.
Enfocadas en el usuario: Las User Stories se enfocan en lo que el usuario quiere lograr, en lugar de en las funcionalidades t√©cnicas del sistema.
Estructura cl√°sica: Generalmente siguen el formato: "Como un [tipo de usuario], quiero [realizar una acci√≥n] para [obtener un beneficio]".
Priorizaci√≥n y estimaci√≥n: Las User Stories se priorizan, y se les asigna un esfuerzo estimado por parte del equipo de desarrollo en caso de que sea una de las variables a tener en cuenta en la priorizaci√≥n.
Conversaci√≥n y confirmaci√≥n: Las User Stories fomentan la conversaci√≥n entre los responsables de producto, los stakeholders y el equipo t√©cnico, y se confirman una vez que la funcionalidad se ha implementado.
Evoluci√≥n iterativa: A medida que el proyecto avanza, las User Stories pueden evolucionar y cambiar para adaptarse a las necesidades cambiantes.


Pero qui√©n escribe las User Stories?
En el contexto de metodolog√≠as √°giles como Scrum, cualquiera puede escribir User Stories. Es responsabilidad del Product Owner asegurarse de que exista un Product Backlog actualizado y priorizado de User Stories, pero eso no significa que el Product Owner sea el √∫nico que las escribe. Los propietarios de productos, las partes interesadas, los gerentes de productos y otros miembros del equipo de negocios participan en la redacci√≥n de User Stories. Se recomienda que la redacci√≥n de User Stories sea un esfuerzo colaborativo de todo el equipo √°gil, lo que incluye al Product Owner, Business Analyst, desarrolladores, testers y cualquier otro rol relevante en el equipo.

Las User Stories son una herramienta central para debatir y validar las necesidades de los usuarios y trabajar en su implementaci√≥n. Proporcionan un lenguaje universal que los miembros del equipo, las partes interesadas y los clientes entienden y hablan, lo que facilita la colaboraci√≥n y el entendimiento mutuo.

En la pr√°ctica, esto significa que las User Stories se utilizan para desarrollar una comprensi√≥n del producto deseado por el usuario y para guiar el desarrollo del software de manera incremental y centrada en el valor

Como crear buenas user stories
Enfocarse en el usuario:
Las user stories deben estar escritas desde la perspectiva del usuario final, no desde la perspectiva interna de la organizaci√≥n.
Utilizar personajes o "personas" para entender mejor las necesidades y objetivos de los usuarios.
Mantener un formato simple y conciso:
Seguir el formato est√°ndar: "Como [tipo de usuario], quiero [realizar una acci√≥n] para [obtener un beneficio]".
Evitar detalles t√©cnicos o instrucciones de implementaci√≥n.
Mantener las historias lo suficientemente peque√±as y entregables en un sprint.
Priorizar y estimar:
Priorizar las historias de usuario en funci√≥n de su valor para el negocio y el usuario.
Estimar el esfuerzo requerido para implementar cada historia.
Fomentar la colaboraci√≥n:
Escribir las historias de usuario de manera colaborativa con el equipo de desarrollo.
Usar las historias de usuario como punto de partida para conversaciones m√°s profundas.
Incluir criterios de aceptaci√≥n:
Definir claramente los criterios que deben cumplirse para considerar una historia "terminada".
Evitar centrarse en c√≥mo se construir√° la funcionalidad.
Mantener las historias actualizadas:
Estar preparado para evolucionar y refinar las historias a medida que el proyecto avanza.
Utilizar t√©cnicas como el User Story Mapping para organizar y priorizar las historias.
Siguiendo estos pasos, se pueden crear user stories efectivas que mantengan el enfoque en las necesidades de los usuarios, faciliten la colaboraci√≥n del equipo y gu√≠en el desarrollo del producto de manera √°gil y centrada en el valor.


Estructura basica de una User Story
Formato est√°ndar: "Como [tipo de usuario], quiero [realizar una acci√≥n] para [obtener un beneficio]".
Descripci√≥n: Una descripci√≥n concisa y en lenguaje natural de la funcionalidad que el usuario desea.
Criterios de Aceptaci√≥n: Condiciones espec√≠ficas que deben cumplirse para considerar la User Story como "terminada", √©stos deberian de seguir un formato similar a ‚ÄúDado que‚Äù [contexto inicial], "cuando‚Äù [acci√≥n realizada], ‚Äúentonces‚Äù [resultado esperado].
Notas adicionales:  Notas que puedan ayudar al desarrollo de la historia
Tareas: Lista de tareas y subtareas para que esta historia pueda ser completada

Ejemplos de User Story
Desarrollo de Productos:"Como gerente de producto, quiero una manera en que los miembros del equipo puedan entender c√≥mo las tareas individuales contribuyen a los objetivos, para que puedan priorizar mejor su trabajo."
Experiencia del Cliente:"Como cliente recurrente, espero que mi informaci√≥n quede guardada para crear una experiencia de pago m√°s fluida, para que pueda completar mis compras de manera r√°pida y sencilla."
Aplicaci√≥n M√≥vil:"Como usuario frecuente de la aplicaci√≥n, quiero una forma de simplificar la informaci√≥n relevante de la manera m√°s r√°pida posible, para poder acceder a la informaci√≥n que necesito de manera eficiente."
Estos ejemplos muestran c√≥mo las User Stories se enfocan en las necesidades y objetivos de los usuarios finales, en lugar de en las funcionalidades t√©cnicas. La estructura simple y el lenguaje natural ayudan a que todos los miembros del equipo, incluyendo stakeholders no t√©cnicos, puedan entender y colaborar en el desarrollo del producto.


Ejemplo completo:

Tal y como se mostr√≥ en el primer tema, una estructura cl√°sica de User Story podr√≠a ser:

T√≠tulo de la Historia de Usuario: 

Como [rol del usuario],
quiero [acci√≥n que desea realizar el usuario],
para que [beneficio que espera obtener el usuario].
Criterios de Aceptaci√≥n:

[Detalle espec√≠fico de funcionalidad]
[Detalle espec√≠fico de funcionalidad]
[Detalle espec√≠fico de funcionalidad]
Notas Adicionales:

[Cualquier consideraci√≥n adicional]
Historias de Usuario Relacionadas:

[Relaciones con otras historias de usuario]
 



Como la AI puede ayudarnos a crear nuestras User Stories
La inteligencia artificial puede ser de gran ayuda en el proceso de identificaci√≥n, creaci√≥n, evaluaci√≥n, revisi√≥n y priorizaci√≥n de User Stories de las siguientes formas:

Identificaci√≥n: La IA puede analizar el PRD y otras fuentes de datos para identificar autom√°ticamente las necesidades y requerimientos de los usuarios que luego se pueden convertir en User Stories.
Creaci√≥n: Utilizando t√©cnicas de generaci√≥n de lenguaje natural, la IA puede ayudar a redactar nuevas User Stories basadas en las necesidades del usuario y los requisitos del producto.
Evaluaci√≥n: La IA puede utilizar algoritmos de aprendizaje autom√°tico para evaluar y validar las User Stories, identificando posibles inconsistencias, lagunas o conflictos en los requisitos.
Revisi√≥n: La IA puede ayudar en la revisi√≥n de las User Stories, proporcionando recomendaciones para mejorar la claridad, coherencia y completitud de las historias.
Priorizaci√≥n: Bas√°ndose en ciertos criterios predefinidos, la IA puede ayudar a priorizar las User Stories en funci√≥n de su valor para el usuario, complejidad, dependencias y otros factores relevantes.
Al aprovechar la inteligencia artificial en el proceso de creaci√≥n y gesti√≥n de User Stories, los equipos de desarrollo pueden optimizar su tiempo y recursos, garantizando que las historias est√©n bien definidas, alineadas con las necesidades del usuario y priorizadas de manera efectiva para el √©xito del producto.

Prompt para detectar posibles problemas y sugerir mejoras:

Analiza las funcionalidades existentes del sistema de alquiler de bicicletas para identificar los cinco problemas m√°s comunes que los usuarios podr√≠an enfrentar y sugerir mejoras

Respuesta ü§ñ

An√°lisis de Problemas Comunes:

Disponibilidad limitada en horas pico: Sugerir un sistema din√°mico de precios o reservas anticipadas para mejorar la disponibilidad.
Mantenimiento de bicicletas: Implementar un sistema automatizado para reportar y rastrear problemas de mantenimiento, basado en el feedback del usuario y sensores IoT.
Dificultad en la localizaci√≥n de estaciones: Mejorar la interfaz de usuario con mapas m√°s claros y opciones de realidad aumentada para encontrar estaciones cercanas f√°cilmente.
Integraci√≥n con otros medios de transporte: Proporcionar una opci√≥n en la app para integrar la planificaci√≥n de rutas que incluya otros modos de transporte p√∫blico.
Soporte al cliente deficiente: Establecer un sistema de atenci√≥n al cliente m√°s reactivo y accesible mediante chatbots de IA y l√≠neas directas de soporte.




2. Priorizaci√≥n del Backlog de Producto
Para priorizar eficazmente el backlog de un proyecto de desarrollo de software, especialmente en un contexto Agile, se deben considerar m√∫ltiples factores que afectan tanto la entrega del proyecto como la satisfacci√≥n del usuario final. Aqu√≠ se detallan los elementos y consideraciones esenciales para una priorizaci√≥n efectiva:

Factores para la Priorizaci√≥n del Backlog
Valor del Negocio: Identificar las user stories y mejoras que aportan el mayor valor al negocio o a los usuarios finales. Esto incluye impacto en la retenci√≥n de usuarios, atractivo para nuevos usuarios y potencial de ingresos.
Urgencia: Determinar qu√© caracter√≠sticas son m√°s urgentes en t√©rminos de necesidades del mercado o compromisos con los stakeholders.
Dependencias: Reconocer y priorizar tareas que otras tareas dependen para su implementaci√≥n. Esto asegura un flujo de trabajo l√≥gico y eficiente.
Coste de implementaci√≥n: Considerar el esfuerzo, los recursos y el tiempo necesarios para cada tarea. Priorizar aquellas con la mejor relaci√≥n costo-beneficio.
Riesgos y obst√°culos potenciales: Evaluar los riesgos asociados con cada user story o mejora y su impacto potencial en el proyecto.
Feedback del usuario: Integrar las opiniones y preferencias de los usuarios, especialmente en √°reas cr√≠ticas de la interfaz de usuario y la experiencia del usuario.
Madurez tecnol√≥gica: Considerar la madurez y la viabilidad de las soluciones tecnol√≥gicas propuestas para cada tarea.
Proceso de priorizaci√≥n
Revisi√≥n de Stakeholders: Involucrar a los stakeholders clave en el proceso de priorizaci√≥n para asegurar que el backlog refleje los objetivos del negocio.
Sesiones de Priorizaci√≥n con el Equipo: Utilizar t√©cnicas como Planning Poker o la matriz de Eisenhower para consensuar la importancia de cada tarea.
Iteraci√≥n y Reevaluaci√≥n: El backlog debe ser din√°mico, reevaluando y ajustando las prioridades regularmente a medida que avanza el proyecto y surgen nuevos datos.
Dado que la priorizaci√≥n es una tarea tan cr√≠tica en el devenir de un proyecto de software, y cada vez se tiene m√°s en cuenta la opini√≥n de los programadores, te recomiendo ver los recursos adicionales sobre este tema al final del m√≥dulo.


Ejemplo: Uso de IA para priorizar el Backlog
Siguiendo con el servicio de reserva de bicicletas, a continuaci√≥n te mostramos un ejemplo de c√≥mo usar las historias de usuario creadas para convertirlo en un backlog priorizado:

Prompt:

Considera el backlog de producto creado anteriormente para el sistema de reserva de bicicletas:

User Stories

User Story 1: Turista Explorador. Como un turista que visita la ciudad por primera vez, quiero reservar una bicicleta f√°cilmente desde mi smartphone para explorar los lugares tur√≠sticos recomendados.
User Story 2: Residente Local. Como un residente que usa la bicicleta diariamente, quiero poder programar reservas recurrentes para asegurar mi transporte a la hora de ir al trabajo.
[...]

Estima por cada item en el backlog (genera una tabla markdown):

Impacto en el usuario y valor del negocio.
Urgencia basada en tendencias del mercado y feedback de usuarios.
Complejidad y esfuerzo estimado de implementaci√≥n.
Riesgos y dependencias entre tareas.
Respuesta ü§ñ

Para evaluar y priorizar el backlog utilizando un algoritmo de aprendizaje autom√°tico, primero es esencial definir los criterios de evaluaci√≥n y luego asignar una puntuaci√≥n a cada √≠tem del backlog. Las siguientes categor√≠as pueden ser consideradas para cada √≠tem:

Criterios de Priorizaci√≥n:

Impacto en el usuario y valor del negocio
Urgencia basada en tendencias del mercado y feedback de usuarios
Complejidad y esfuerzo estimado de implementaci√≥n
Riesgos y dependencias entre tareas
Estimaci√≥n de Priorizaci√≥n:



Explicaci√≥n de la Tabla:

User Stories: Las historias enfocadas en el turista y el residente local tienen alto impacto y urgencia media a alta debido a su potencial para mejorar significativamente la experiencia del usuario y fidelizar clientes.
Optimizaci√≥n de Rutas y Recomendaciones con IA: Este √≠tem tiene un alto impacto y es urgente, pero tambi√©n es complejo y podr√≠a presentar m√°s riesgos debido a la necesidad de tecnolog√≠a avanzada y integraci√≥n con sistemas existentes.
Problemas y Mejoras: Los problemas como la disponibilidad en horas pico y el mantenimiento de bicicletas tienen un alto impacto, pues afectan directamente la satisfacci√≥n y retenci√≥n del usuario.
Esta tabla es una representaci√≥n simplificada y deber√≠a ser ajustada con datos m√°s espec√≠ficos y an√°lisis detallado para una priorizaci√≥n precisa en un contexto real. 



Conclusi√≥n
El backlog en Agile es una herramienta vital que evoluciona con el proyecto, garantizando que el equipo se mantenga enfocado y alineado con las necesidades del usuario. 

Se ha compartido un ejemplo para mostrar c√≥mo la integraci√≥n de IA en esta fase no solo aumenta la eficiencia sino que tambi√©n mejora la calidad y relevancia de los elementos que se incluyen, permitiendo una gesti√≥n m√°s din√°mica y adaptativa del desarrollo del producto.

Como siempre, la calidad del contexto introducido es clave para obtener respuestas de calidad. Y como siempre, aunque esto puede ser una muy buena semilla que agilice la creaci√≥n de artefactos y documentaci√≥n, debemos revisar de manera concienzuda la respuesta para retocar, ampliar o corregir aquello que, seg√∫n nuestro criterio y nuestra experiencia como ingenieros/as, consideremos.

# PROMPT EFC-1
Ejecutar los siguientes pasos documentando todo en el fichero UserStories-EFC difiniendo claramente donde est√° cada punto, y la opini√≥n sobre la tabla comparativa.

Para tu ejercicio, sigue este orden:
PROMPT INICIAL ‚Üí 1.1 ‚Üí 2.1 (experimenta con 2.2, 2.3, 2.4) ‚Üí 3.1 ‚Üí 4.1 + 4.3
Para el punto 2 del ejercicio (experimentar con diferentes prompts de backlog):
Ejecuta los 4 prompts de la Parte 2 (2.1, 2.2, 2.3, 2.4)
Compara los resultados
Usa la tabla comparativa incluida para analizar ventajas/desventajas
Documenta cu√°l te dio mejores resultados y por qu√©
Recomendaci√≥n para LTI ATS:
User Stories: Prompt 1.1 (completo de una vez)
Backlog: Prompt 2.1 (MoSCoW) - m√°s r√°pido y alineado con tu PRD
Tickets: Prompt 3.1 (descomposici√≥n t√©cnica)
Estimaci√≥n: Prompt 4.1 (Planning Poker) + 4.3 (riesgos para tickets complejos)


# Prompts para Generaci√≥n de User Stories y Backlog - LTI ATS

## Contexto del Proyecto (Memory Bank)

### Informaci√≥n del Sistema
**Proyecto:** LTI ATS (Applicant Tracking System)
**Descripci√≥n:** Sistema de seguimiento de candidatos de nueva generaci√≥n que integra IA avanzada, colaboraci√≥n en tiempo real y automatizaci√≥n inteligente para transformar los procesos de reclutamiento.

### Documentaci√≥n Base Disponible
- **PRD Completo:** Documento LTI-EFC.md que contiene:
  - Visi√≥n de producto y estrategia
  - 20 funcionalidades priorizadas (MVP hasta Won't Have v1)
  - 3 casos de uso esenciales detallados (CU-01, CU-02, CU-03)
  - Modelo de datos completo (7 entidades principales)
  - Arquitectura de microservicios con 10 componentes
  - Diagramas de casos de uso y ERD

### Actores Principales del Sistema
- **Reclutador:** Gestiona ofertas y procesos de selecci√≥n
- **Manager de Contrataci√≥n:** Aprueba ofertas y toma decisiones finales
- **Entrevistador/Hiring Team:** Eval√∫a candidatos
- **Candidato:** Aplica a ofertas y consulta su estado
- **Sistema de IA:** Procesa CVs, rankea candidatos, genera contenido

### Funcionalidades Prioritarias (Must Have - MVP)
1. Gesti√≥n de Ofertas de Empleo
2. Publicaci√≥n Multicanal
3. Recepci√≥n y Parsing de CVs con IA
4. Pipeline de Candidatos (Kanban)
5. Screening con IA
6. Perfiles de Candidato
7. Comunicaci√≥n automatizada con Candidatos
8. Programaci√≥n de Entrevistas
9. Colaboraci√≥n en Evaluaci√≥n
10. Dashboard y Reporting

---

## PROMPT INICIAL (Contexto para la IA)

```
# Contexto del Proyecto LTI ATS

Eres un Product Manager y Business Analyst senior especializado en sistemas de Recursos Humanos y metodolog√≠as √°giles.

Est√°s trabajando en LTI ATS, un sistema de seguimiento de candidatos (Applicant Tracking System) de nueva generaci√≥n que integra:
- **Inteligencia Artificial** para screening autom√°tico y scoring de candidatos
- **Colaboraci√≥n en tiempo real** para evaluaciones en equipo
- **Automatizaci√≥n inteligente** de comunicaciones y workflows

## Informaci√≥n Clave del Proyecto

### Usuarios Objetivo
- Empresas medianas (50-500 empleados) con equipos HR de 2-10 personas
- Scale-ups tecnol√≥gicas con alto volumen de contrataci√≥n

### Valor Diferencial
- Reducci√≥n del 60% en tiempo de screening mediante IA
- Matching inteligente que mejora compatibilidad en 40%
- LTI Copilot: asistente IA conversacional integrado
- Colaboraci√≥n sincr√≥nica sin reuniones adicionales

### Stack Tecnol√≥gico
- **Frontend:** React + TypeScript
- **Backend:** Microservicios (Java Spring Boot, Node.js, Python FastAPI)
- **Datos:** PostgreSQL, Redis, Elasticsearch
- **IA:** ML models propios + integraci√≥n con LLMs (OpenAI/Anthropic)

### Casos de Uso Esenciales Documentados
1. **CU-01:** Crear y Publicar Oferta de Empleo (con asistencia de IA)
2. **CU-02:** Revisar y Filtrar Candidatos con IA (parsing + scoring)
3. **CU-03:** Colaborar en la Evaluaci√≥n de un Candidato (scorecards + votaci√≥n)

### Modelo de Datos Principal
- **JobPosting** (ofertas de empleo)
- **Candidate** (candidatos)
- **Application** (candidaturas con scoring IA)
- **Interview** (entrevistas programadas)
- **Evaluation** (evaluaciones con scorecards)
- **User** (usuarios del sistema: recruiters, managers, interviewers)
- **Comment** (comentarios colaborativos en tiempo real)

**Documento PRD Completo:** Disponible en LTI-EFC.md con 930 l√≠neas de especificaciones detalladas.

Tu misi√≥n es generar documentaci√≥n √°gil de calidad para iniciar la implementaci√≥n del MVP.
```

---

# PARTE 1: Generaci√≥n de User Stories

## PROMPT 1.1 - Generar User Stories (Enfoque Completo)

```
Bas√°ndote en el PRD de LTI ATS (documento LTI-EFC.md) y los 3 casos de uso esenciales documentados, genera un conjunto completo de User Stories para el MVP siguiendo estas instrucciones:

## Estructura Requerida para Cada User Story

T√≠tulo de la Historia de Usuario: [Nombre descriptivo y conciso]

**Como** [rol del usuario],
**quiero** [acci√≥n que desea realizar el usuario],
**para que** [beneficio que espera obtener el usuario].

**Criterios de Aceptaci√≥n:**
- Dado que [contexto inicial],
  cuando [acci√≥n realizada],
  entonces [resultado esperado].
- [Repetir para cada escenario relevante]

**Notas Adicionales:**
- [Consideraciones t√©cnicas, restricciones, integraciones necesarias]

**Tareas T√©cnicas:**
- [ ] Tarea 1
- [ ] Tarea 2
- [ ] Tarea 3

**Historias de Usuario Relacionadas:**
- [Referencias a otras US dependientes o relacionadas]

---

## Requisitos Espec√≠ficos

1. **Cobertura:** Genera al menos 8-10 User Stories que cubran:
   - Gesti√≥n de ofertas de empleo (creaci√≥n, edici√≥n, publicaci√≥n)
   - Recepci√≥n y screening de candidatos con IA
   - Evaluaci√≥n colaborativa de candidatos
   - Comunicaci√≥n automatizada
   - Dashboard de m√©tricas

2. **Priorizaci√≥n:** Enf√≥cate en funcionalidades **Must Have** y **Should Have** del PRD.

3. **Actores:** Incluye User Stories para:
   - Reclutador
   - Manager de Contrataci√≥n
   - Entrevistador
   - Candidato (al menos 1)

4. **Nivel de Detalle:**
   - Criterios de aceptaci√≥n espec√≠ficos y medibles
   - Al menos 3-5 criterios por User Story
   - Tareas t√©cnicas realistas (frontend, backend, IA, integraciones)

5. **Formato:** Usa markdown con emojis para roles (üìã Reclutador, üëî Manager, üé§ Entrevistador, üë§ Candidato).

## Ejemplo de Referencia

**US-001: Crear Oferta de Empleo con Asistencia de IA**

**Como** üìã Reclutador,
**quiero** crear una nueva oferta de empleo con sugerencias autom√°ticas de IA para la descripci√≥n,
**para que** pueda publicar ofertas optimizadas en menos tiempo.

**Criterios de Aceptaci√≥n:**
- Dado que soy un Reclutador autenticado,
  cuando accedo a "Nueva Oferta" e ingreso t√≠tulo, departamento y ubicaci√≥n,
  entonces el sistema activa LTI Copilot y me sugiere una descripci√≥n optimizada en menos de 5 segundos.

- Dado que reviso la descripci√≥n generada por IA,
  cuando edito o acepto la sugerencia y completo requisitos obligatorios,
  entonces puedo guardar la oferta como borrador o enviarla a aprobaci√≥n.

- Dado que selecciono canales de publicaci√≥n,
  cuando el Manager aprueba la oferta,
  entonces el sistema publica autom√°ticamente en todos los canales y me muestra los enlaces activos.

**Notas Adicionales:**
- Integraci√≥n con OpenAI/Anthropic para generaci√≥n de descripciones
- Soporte para plantillas personalizables por departamento
- Notificaci√≥n en tiempo real al Manager para aprobaci√≥n

**Tareas T√©cnicas:**
- [ ] Dise√±ar formulario de creaci√≥n en React con validaciones
- [ ] Crear endpoint POST /api/job-postings en Recruitment Service
- [ ] Integrar llamada a LTI Copilot (AI Service) para generaci√≥n de descripci√≥n
- [ ] Implementar workflow de aprobaci√≥n con notificaciones
- [ ] Desarrollar publicaci√≥n multicanal (Integration Service)

**Historias de Usuario Relacionadas:**
- US-002: Publicar Oferta en Job Boards
- US-009: Recibir Notificaci√≥n de Oferta Pendiente de Aprobaci√≥n

---

Genera ahora las User Stories siguiendo esta estructura y requisitos.
```

---

## PROMPT 1.2 - Generar User Stories (Enfoque Iterativo por Actor)

```
Vamos a generar User Stories para LTI ATS de forma iterativa, actor por actor. Empecemos con el **Reclutador**.

Bas√°ndote en el PRD (LTI-EFC.md) y las funcionalidades Must Have del MVP, genera 4-5 User Stories para el **Reclutador** que cubran:

1. Creaci√≥n y publicaci√≥n de ofertas de empleo
2. Revisi√≥n de candidatos con asistencia de IA
3. Gesti√≥n del pipeline de candidatos
4. Programaci√≥n de entrevistas

Usa la estructura est√°ndar:
- T√≠tulo descriptivo
- Como [rol] quiero [acci√≥n] para que [beneficio]
- Criterios de Aceptaci√≥n en formato Dado-Cuando-Entonces (m√≠nimo 3 por US)
- Notas Adicionales (t√©cnicas)
- Tareas T√©cnicas (4-6 por US)
- Historias Relacionadas

Recuerda incluir consideraciones de UX, integraciones con IA, y notificaciones en tiempo real donde aplique.

---

**[Despu√©s de recibir la respuesta de la IA, continuar con:]**

Perfecto. Ahora genera 3-4 User Stories para el **Manager de Contrataci√≥n** que incluyan:
1. Aprobaci√≥n de ofertas de empleo
2. Revisi√≥n de evaluaciones de candidatos
3. Toma de decisiones colaborativas (votaciones)
4. Visualizaci√≥n de m√©tricas del proceso

---

**[Despu√©s de recibir la respuesta, continuar con:]**

Excelente. Genera 2-3 User Stories para el **Entrevistador/Hiring Team**:
1. Completar evaluaci√≥n post-entrevista con scorecard
2. Colaborar con comentarios en tiempo real
3. Votar sobre candidatos

---

**[Finalmente:]**

Por √∫ltimo, genera 1-2 User Stories desde la perspectiva del **Candidato**:
1. Aplicar a una oferta de empleo
2. Consultar el estado de su candidatura en el portal
```

---

# PARTE 2: Creaci√≥n del Backlog de Producto

## PROMPT 2.1 - Backlog con Priorizaci√≥n MoSCoW (RECOMENDADO)

```
Ahora que tenemos las User Stories generadas para LTI ATS, crea un **Product Backlog priorizado** siguiendo estos pasos:

## Paso 1: Lista Completa de User Stories
Crea una tabla markdown con todas las User Stories generadas que incluya:
- ID (US-001, US-002, etc.)
- T√≠tulo
- Actor principal
- √âpica relacionada (agrupa por funcionalidad: Gesti√≥n de Ofertas, Screening con IA, Evaluaci√≥n Colaborativa, etc.)

## Paso 2: An√°lisis de Priorizaci√≥n
Para cada User Story, eval√∫a y asigna puntuaci√≥n (1-5) en:

| Criterio | Descripci√≥n |
|----------|-------------|
| **Valor de Negocio** | Impacto directo en objetivos del MVP (reducir time-to-hire, mejorar matching) |
| **Urgencia** | ¬øEs bloqueante para otras funcionalidades? ¬øNecesaria para demo/lanzamiento? |
| **Complejidad T√©cnica** | Esfuerzo de implementaci√≥n (1=simple, 5=muy complejo) |
| **Riesgo** | Incertidumbre tecnol√≥gica, dependencias externas |
| **Dependencias** | ¬øCu√°ntas otras US dependen de esta? |

## Paso 3: Priorizaci√≥n MoSCoW
Clasifica cada User Story en:
- **Must Have:** Cr√≠ticas para el MVP funcional
- **Should Have:** Importantes pero no bloqueantes
- **Could Have:** Deseables si hay tiempo
- **Won't Have (v1):** Para versiones futuras

## Paso 4: Backlog Final Priorizado
Crea una tabla markdown con este formato:

| Prioridad | ID | T√≠tulo | Actor | √âpica | Valor Negocio | Urgencia | Complejidad | Riesgo | Dependencias | MoSCoW | Sprint Sugerido |
|-----------|----|----|-------|-------|---------------|----------|-------------|--------|--------------|--------|-----------------|
| 1 | US-001 | Crear Oferta con IA | Reclutador | Gesti√≥n Ofertas | 5 | 5 | 3 | 2 | 0 | Must Have | Sprint 1 |
| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |

Ordena la tabla por prioridad descendente (las m√°s prioritarias primero).

## Paso 5: Justificaci√≥n de Priorizaci√≥n
Explica brevemente (2-3 p√°rrafos):
- **Criterios de decisi√≥n:** ¬øQu√© factores pesaron m√°s en la priorizaci√≥n?
- **L√≥gica del ordenamiento:** ¬øPor qu√© las primeras US son las m√°s cr√≠ticas?
- **Estrategia de sprints:** ¬øC√≥mo se distribuir√≠an en sprints de 2 semanas?

---

**Contexto del MVP:**
- Objetivo: Sistema funcional end-to-end en 3 meses (6 sprints)
- Equipo: 5 devs full-stack + 1 ML engineer + 1 QA
- MVP debe permitir: publicar oferta ‚Üí recibir CVs ‚Üí screening IA ‚Üí evaluar colaborativamente ‚Üí contratar

Genera el backlog priorizado completo ahora.
```

---

## PROMPT 2.2 - Backlog con Priorizaci√≥n RICE Score

```
Crea un Product Backlog para LTI ATS usando el m√©todo **RICE Score** para priorizaci√≥n objetiva.

## Metodolog√≠a RICE

Para cada User Story, calcula:

**RICE Score = (Reach √ó Impact √ó Confidence) / Effort**

Donde:
- **Reach (Alcance):** ¬øCu√°ntos usuarios/procesos afecta por mes? (escala 0-1000)
  - Todas las contrataciones = 100
  - Todos los reclutadores = 50
  - Solo managers = 10

- **Impact (Impacto):** ¬øCu√°nto mejora la experiencia/proceso? (0.25, 0.5, 1, 2, 3)
  - 3 = Impacto masivo (reducci√≥n 50%+ en tiempo)
  - 2 = Impacto alto
  - 1 = Impacto medio
  - 0.5 = Impacto bajo
  - 0.25 = Impacto m√≠nimo

- **Confidence (Confianza):** ¬øQu√© certeza tenemos de Reach/Impact? (50%, 80%, 100%)
  - 100% = Datos s√≥lidos o funcionalidad probada
  - 80% = Estimaci√≥n razonable
  - 50% = Suposici√≥n/hip√≥tesis

- **Effort (Esfuerzo):** Estimaci√≥n en **Story Points** (1, 2, 3, 5, 8, 13, 21)
  - 1 = Tarea trivial (< 1 d√≠a)
  - 3 = Funcionalidad simple (2-3 d√≠as)
  - 5 = Funcionalidad media (4-5 d√≠as)
  - 8 = Funcionalidad compleja (1-2 semanas)
  - 13 = Muy complejo (2-3 semanas)

## Formato de Entrega

### Tabla de An√°lisis RICE

| ID | T√≠tulo | Reach | Impact | Confidence | Effort (SP) | RICE Score | Ranking |
|----|--------|-------|--------|------------|-------------|------------|---------|
| US-001 | Crear Oferta con IA | 100 | 2 | 80% | 5 | 32.0 | 1 |
| ... | ... | ... | ... | ... | ... | ... | ... |

### Backlog Priorizado (Top 10)

Lista las 10 User Stories con mayor RICE Score, explicando para cada una:
1. **Por qu√© el RICE Score es alto:** Justificaci√≥n de los valores asignados
2. **Riesgos identificados:** Dependencias, incertidumbres t√©cnicas
3. **Quick wins:** Marca aquellas con RICE alto y Effort bajo (primer√≠simas)

### Distribuci√≥n en Sprints

Agrupa las US en sprints de 40 Story Points cada uno, respetando dependencias:
- **Sprint 1:** [Lista de US-IDs] - Total: X SP
- **Sprint 2:** [Lista de US-IDs] - Total: X SP
- ...

---

**Restricciones del MVP:**
- 6 sprints disponibles (3 meses)
- Capacidad del equipo: 40 SP por sprint
- Demo al stakeholder en Sprint 3

Genera el an√°lisis RICE y backlog priorizado ahora.
```

---

## PROMPT 2.3 - Backlog con Priorizaci√≥n Kano Model + Value vs Effort

```
Crea un Product Backlog para LTI ATS combinando el **Modelo Kano** para clasificar features y una **matriz Value vs Effort** para priorizaci√≥n visual.

## Paso 1: Clasificaci√≥n Kano

Clasifica cada User Story seg√∫n el Modelo Kano:

| Categor√≠a Kano | Descripci√≥n | Estrategia |
|----------------|-------------|------------|
| **Basic (B√°sico)** | Features que los usuarios esperan. Su ausencia causa insatisfacci√≥n, pero su presencia no aumenta satisfacci√≥n. | Implementar S√ç o S√ç |
| **Performance (Desempe√±o)** | Features donde "m√°s es mejor". Aumentan satisfacci√≥n linealmente. | Implementar bien, core del MVP |
| **Excitement (Sorpresa)** | Features inesperados que deleitan. Su ausencia no molesta pero su presencia genera WOW. | Implementar 1-2 para diferenciaci√≥n |
| **Indifferent (Indiferente)** | Features que no afectan satisfacci√≥n. | Evitar/Posponer |

**Para LTI ATS:**
- **Basic:** Crear ofertas, ver candidatos, enviar emails
- **Performance:** Screening con IA, colaboraci√≥n en tiempo real, dashboards
- **Excitement:** LTI Copilot generando preguntas de entrevista personalizadas, scoring predictivo de retenci√≥n

## Paso 2: Matriz Value vs Effort

Crea una tabla clasificando cada US en cuadrantes:

```
         HIGH VALUE
            ‚îÇ
  Big Bets  ‚îÇ  Quick Wins
     ‚è∞     ‚îÇ     ‚ö°
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
     üí∞     ‚îÇ     ‚ùå
 Money Pit  ‚îÇ  Time Sinks
            ‚îÇ
         LOW VALUE

      LOW        HIGH
       EFFORT
```

| US-ID | T√≠tulo | Kano | Value (1-10) | Effort (SP) | Cuadrante | Prioridad |
|-------|--------|------|--------------|-------------|-----------|-----------|
| US-001 | Crear Oferta con IA | Performance | 9 | 5 | Quick Win | P0 |
| US-005 | Video entrevistas nativas | Excitement | 7 | 13 | Big Bet | P2 |
| US-008 | Exportar reportes a PDF | Indifferent | 3 | 3 | Time Sink | P3 |

## Paso 3: Estrategia de Priorizaci√≥n

**Sprint 1-2 (Primeros 4 semanas):**
- Todas las **Basic** (no negociables)
- Top 3 **Quick Wins** (alto value, bajo effort)

**Sprint 3-4:**
- Top **Performance** features
- 1 **Big Bet** estrat√©gico

**Sprint 5-6:**
- Restantes **Performance**
- 1 **Excitement** feature para diferenciaci√≥n
- Pulido y testing

## Formato de Entrega

1. **Tabla Kano + Value vs Effort** con todas las US
2. **Visualizaci√≥n ASCII** de la matriz (opcional pero recomendado)
3. **Backlog priorizado** con esta estructura:

### üî• Prioridad P0 (Must Have - Sprint 1-2)
- US-001: [T√≠tulo] - [Kano: Basic/Performance] - Value: X, Effort: Y SP
- US-002: ...

### ‚ö†Ô∏è Prioridad P1 (Should Have - Sprint 3-4)
- US-005: ...

### üí° Prioridad P2 (Could Have - Sprint 5-6)
- US-010: ...

### üö´ Prioridad P3 (Won't Have v1)
- US-015: ...

4. **An√°lisis de trade-offs:** Explica 2-3 decisiones dif√≠ciles de priorizaci√≥n.

---

Genera el an√°lisis completo ahora usando las User Stories de LTI ATS.
```

---

## PROMPT 2.4 - Backlog con Priorizaci√≥n Story Mapping

```
Crea un Product Backlog para LTI ATS usando **User Story Mapping** para visualizar el journey del usuario y priorizar por releases.

## Estructura del Story Map

Organiza las User Stories en un mapa jer√°rquico:

```
ACTIVIDADES (Backbone - pasos principales del proceso)
    ‚îú‚îÄ‚îÄ Publicar Oferta
    ‚îú‚îÄ‚îÄ Recibir Candidatos
    ‚îú‚îÄ‚îÄ Screening
    ‚îú‚îÄ‚îÄ Entrevistas
    ‚îú‚îÄ‚îÄ Decidir
    ‚îî‚îÄ‚îÄ Contratar

TAREAS (Walking Skeleton)
    ‚îî‚îÄ‚îÄ [User Stories espec√≠ficas bajo cada actividad]

RELEASES
    ‚îî‚îÄ‚îÄ MVP (1¬™ fila), v1.1 (2¬™ fila), v2.0 (3¬™ fila)
```

## Formato de Entrega

### 1. Story Map Completo

Crea una tabla markdown con este formato:

| Actividad | MVP (Release 1) | v1.1 (Release 2) | v2.0 (Release 3) |
|-----------|-----------------|------------------|------------------|
| **1. Publicar Oferta** | US-001: Crear oferta b√°sica<br>US-002: Publicar en web | US-015: LTI Copilot descripci√≥n<br>US-016: Multiposting job boards | US-030: A/B testing descripciones |
| **2. Recibir Candidatos** | US-003: Formulario aplicaci√≥n<br>US-004: Upload CV | US-017: Parsing CV avanzado | US-031: LinkedIn auto-import |
| **3. Screening** | US-005: Vista lista candidatos<br>US-006: Filtros manuales | US-007: Scoring con IA<br>US-008: Ranking autom√°tico | US-032: ML predictivo retenci√≥n |
| **4. Entrevistas** | US-009: Agendar entrevista<br>US-010: Integraci√≥n calendario | US-018: Sugerencias IA preguntas | US-033: Video entrevistas nativas |
| **5. Decidir** | US-011: Scorecard evaluaci√≥n | US-012: Votaci√≥n colaborativa<br>US-013: Comentarios tiempo real | US-034: Analytics decisiones |
| **6. Contratar** | US-014: Cambiar estado a "Hired" | US-019: Generar carta oferta | US-035: Onboarding workflow |

### 2. Walking Skeleton del MVP

Lista las User Stories m√≠nimas que permiten completar un proceso end-to-end (1 historia por actividad):

1. **US-001:** Crear oferta b√°sica ‚Üí ‚úÖ Oferta publicable
2. **US-003:** Formulario aplicaci√≥n ‚Üí ‚úÖ Candidato en sistema
3. **US-005:** Vista lista candidatos ‚Üí ‚úÖ Reclutador puede ver candidatos
4. **US-009:** Agendar entrevista ‚Üí ‚úÖ Entrevista programada
5. **US-011:** Scorecard evaluaci√≥n ‚Üí ‚úÖ Candidato evaluado
6. **US-014:** Marcar como contratado ‚Üí ‚úÖ Proceso completado

**Estimaci√≥n Walking Skeleton:** X Story Points ‚Üí Entregable en Sprint 1

### 3. Backlog Priorizado por Release

#### Release 1 - MVP (Sprint 1-3)
**Objetivo:** Sistema funcional end-to-end sin IA avanzada
- [ ] US-001: Crear oferta b√°sica (5 SP)
- [ ] US-002: Publicar en web corporativa (3 SP)
- [ ] US-003: Formulario de aplicaci√≥n (3 SP)
- ...
**Total: XX SP | Timeline: 6 semanas**

#### Release 2 - v1.1 (Sprint 4-6)
**Objetivo:** Agregar capacidades de IA y colaboraci√≥n
- [ ] US-007: Scoring de candidatos con IA (13 SP)
- [ ] US-012: Votaci√≥n colaborativa (8 SP)
- ...
**Total: XX SP | Timeline: +6 semanas**

#### Release 3 - v2.0 (Futuro)
**Objetivo:** Features de diferenciaci√≥n y scale
- [ ] US-030: A/B testing de descripciones (8 SP)
- ...

### 4. Justificaci√≥n del Mapa

Explica:
- **¬øPor qu√© este orden de actividades?** L√≥gica del flujo del proceso de reclutamiento
- **¬øC√≥mo se defini√≥ el MVP?** Criterios de la "primera fila"
- **Dependencias cr√≠ticas:** Qu√© US son bloqueantes para otras

---

Genera el Story Map completo con las User Stories de LTI ATS ahora.
```

---

## üìä COMPARATIVA DE PROMPTS - An√°lisis de Efectividad

### Resumen de M√©todos de Priorizaci√≥n

| Prompt | M√©todo | Ventajas | Desventajas | Mejor Para |
|--------|--------|----------|-------------|-----------|
| **2.1** | MoSCoW | Simple, r√°pido, enfoque en valor de negocio | Subjetivo, no cuantifica trade-offs | Equipos nuevos, MVPs r√°pidos |
| **2.2** | RICE Score | Cuantitativo, objetivo, considera esfuerzo | Requiere datos, puede ser fr√≠o | Equipos maduros, productos con hist√≥rico |
| **2.3** | Kano + Value/Effort | Diferencia tipos de valor, visual, estrat√©gico | Complejo, requiere investigaci√≥n de usuario | Productos innovadores, diferenciaci√≥n |
| **2.4** | Story Mapping | Visualiza journey completo, identifica gaps | Toma tiempo, mejor en equipo | Productos complejos, m√∫ltiples releases |

### Recomendaci√≥n por Contexto

**Para LTI ATS espec√≠ficamente:**

ü•á **RECOMENDADO: PROMPT 2.1 (MoSCoW)** - Por:
- MVP debe lanzarse r√°pido (3 meses)
- Equipo peque√±o necesita foco claro
- PRD ya tiene funcionalidades categorizadas (Must/Should/Could/Won't)
- Permite iterar r√°pido sin par√°lisis por an√°lisis

ü•à **Alternativa: PROMPT 2.3 (Kano + Value/Effort)** - Si:
- Quieres identificar 1-2 features "wow" para diferenciarte
- Tienes tiempo para investigaci√≥n de usuarios
- Necesitas justificar priorizaci√≥n a stakeholders

ü•â **Complementario: PROMPT 2.4 (Story Mapping)** - Para:
- Workshop con todo el equipo (1 d√≠a)
- Visualizar roadmap a largo plazo (v1, v2, v3)
- Identificar MVP "walking skeleton"

**No recomendado para este proyecto:**
- ‚ùå PROMPT 2.2 (RICE): Falta hist√≥rico de datos para estimar Reach con precisi√≥n.

---

# PARTE 3: Generaci√≥n de Tickets de Trabajo

## PROMPT 3.1 - Descomposici√≥n T√©cnica de User Story (RECOMENDADO)

```
Has sido asignado como Tech Lead para el Sprint 1 de LTI ATS.

Necesitas descomponer t√©cnicamente la siguiente User Story para la reuni√≥n de Planning:

---

**US-001: Crear Oferta de Empleo con Asistencia de IA**

**Como** üìã Reclutador,
**quiero** crear una nueva oferta de empleo con sugerencias autom√°ticas de IA para la descripci√≥n,
**para que** pueda publicar ofertas optimizadas en menos tiempo.

**Criterios de Aceptaci√≥n:**
1. Dado que soy un Reclutador autenticado, cuando accedo a "Nueva Oferta" e ingreso t√≠tulo, departamento y ubicaci√≥n, entonces el sistema activa LTI Copilot y me sugiere una descripci√≥n optimizada en menos de 5 segundos.
2. Dado que reviso la descripci√≥n generada por IA, cuando edito o acepto la sugerencia y completo requisitos obligatorios, entonces puedo guardar la oferta como borrador o enviarla a aprobaci√≥n.
3. Dado que selecciono canales de publicaci√≥n, cuando el Manager aprueba la oferta, entonces el sistema publica autom√°ticamente en todos los canales y me muestra los enlaces activos.

---

## Tareas Requeridas

Descomp√≥n esta User Story en **Tickets de Trabajo T√©cnicos** siguiendo este formato:

### Estructura de Ticket

**[TIPO-XXX]: T√≠tulo del Ticket**

**Descripci√≥n:**
[Explicaci√≥n t√©cnica clara del trabajo a realizar]

**Contexto de la User Story:**
[Referencia al criterio de aceptaci√≥n que cubre este ticket]

**Tareas T√©cnicas:**
- [ ] Subtarea 1
- [ ] Subtarea 2
- [ ] Subtarea 3

**Criterios de Aceptaci√≥n T√©cnicos:**
- [ ] Criterio t√©cnico 1 (ej: "API responde en < 200ms")
- [ ] Criterio t√©cnico 2 (ej: "Incluye tests unitarios con 80%+ coverage")
- [ ] Criterio t√©cnico 3 (ej: "Maneja errores con c√≥digos HTTP correctos")

**Dependencias:**
- [Otros tickets que deben completarse antes]
- [Servicios/APIs externos necesarios]

**Definici√≥n de Done:**
- [ ] C√≥digo implementado y revisado (PR aprobado)
- [ ] Tests unitarios y de integraci√≥n pasando
- [ ] Documentaci√≥n t√©cnica actualizada
- [ ] Desplegado en ambiente de staging
- [ ] QA validado

**Estimaci√≥n:** [Story Points o Horas]

**Asignado a:** [Especialidad: Frontend / Backend / IA / DevOps]

**Notas T√©cnicas:**
[Consideraciones de arquitectura, decisiones de dise√±o, riesgos]

---

## Requisitos de Descomposici√≥n

1. **Granularidad:** Cada ticket debe ser completable por 1 desarrollador en 0.5-2 d√≠as.

2. **Cobertura T√©cnica:** Genera tickets para:
   - **Frontend:** Componentes React, formularios, validaciones, UX
   - **Backend:** Endpoints API, l√≥gica de negocio, validaciones, persistencia
   - **Base de Datos:** Migraciones, queries, √≠ndices
   - **IA:** Integraci√≥n con LLM, prompts, parsing de respuestas
   - **Testing:** Tests unitarios, integraci√≥n, E2E
   - **DevOps:** Configuraci√≥n, despliegue, monitoreo (si aplica)

3. **Nomenclatura de Tickets:**
   - `FRONT-XXX` para frontend
   - `BACK-XXX` para backend
   - `DATA-XXX` para base de datos
   - `AI-XXX` para IA
   - `TEST-XXX` para testing
   - `DEVOPS-XXX` para infraestructura

4. **Stack T√©cnico de LTI ATS:**
   - **Frontend:** React 18 + TypeScript, Tailwind CSS, React Hook Form, React Query
   - **Backend:** Java Spring Boot (Recruitment Service), Python FastAPI (AI Service), Node.js (otros)
   - **Base de Datos:** PostgreSQL 14
   - **IA:** LangChain + OpenAI GPT-4 / Anthropic Claude

5. **M√≠nimo:** Genera al menos 8-12 tickets t√©cnicos que cubran todo el flujo.

---

## Ejemplo de Ticket

**[FRONT-001]: Implementar Formulario de Creaci√≥n de Oferta con Validaciones**

**Descripci√≥n:**
Desarrollar el componente React del formulario de creaci√≥n de ofertas de empleo que incluye campos b√°sicos (t√≠tulo, departamento, ubicaci√≥n, tipo de contrato, rango salarial) con validaciones en tiempo real y integraci√≥n con el bot√≥n de generaci√≥n de descripci√≥n por IA.

**Contexto de la User Story:**
Cubre el Criterio de Aceptaci√≥n #1: "cuando accedo a 'Nueva Oferta' e ingreso t√≠tulo, departamento y ubicaci√≥n, entonces el sistema activa LTI Copilot".

**Tareas T√©cnicas:**
- [ ] Crear componente `JobPostingForm.tsx` con React Hook Form
- [ ] Implementar validaciones de campos obligatorios y rangos salariales
- [ ] Dise√±ar UI seg√∫n Figma specs con Tailwind CSS
- [ ] Integrar bot√≥n "Generar Descripci√≥n con IA" que llama a AI Service
- [ ] Mostrar loading spinner mientras IA genera contenido
- [ ] Implementar manejo de errores con toast notifications

**Criterios de Aceptaci√≥n T√©cnicos:**
- [ ] Formulario valida campos obligatorios antes de habilitar "Generar con IA"
- [ ] Llamada a API de IA se realiza con debounce de 500ms
- [ ] Errores de API se muestran al usuario con mensajes claros
- [ ] Componente es accesible (WCAG 2.1 AA) con labels y ARIA
- [ ] Tests con React Testing Library cubren casos principales

**Dependencias:**
- `BACK-001`: Endpoint POST /api/job-postings/draft debe estar disponible
- `AI-001`: Endpoint POST /ai/generate-description debe estar disponible
- Dise√±o UI aprobado en Figma

**Definici√≥n de Done:**
- [ ] C√≥digo implementado en feature branch
- [ ] PR revisado y aprobado por 1 dev senior
- [ ] Tests unitarios pasando (coverage > 80%)
- [ ] Storybook stories creadas para componente
- [ ] QA manual completado en staging

**Estimaci√≥n:** 5 Story Points (2 d√≠as)

**Asignado a:** Frontend Developer

**Notas T√©cnicas:**
- Usar React Query para cach√© de llamadas a AI Service
- Implementar optimistic updates para mejor UX
- Considerar rate limiting de AI API (max 3 llamadas por minuto)

---

Genera ahora la descomposici√≥n completa de US-001 en tickets t√©cnicos detallados.
```

---

## PROMPT 3.2 - Tickets con Enfoque Test-Driven

```
Descomp√≥n la User Story seleccionada de LTI ATS siguiendo un **enfoque Test-Driven Development (TDD)**.

Para cada ticket, primero define:

### 1. Tests a Implementar

**Tests Unitarios:**
- [ ] Test 1: Descripci√≥n del caso (Given-When-Then)
- [ ] Test 2: ...

**Tests de Integraci√≥n:**
- [ ] Test 1: ...

**Tests E2E:**
- [ ] Test 1: ...

### 2. Criterios de Aceptaci√≥n Basados en Tests

Cada criterio debe ser un test ejecutable:

```javascript
// Ejemplo Frontend
describe('JobPostingForm', () => {
  it('should call AI service when title, department and location are filled', async () => {
    // Given: formulario con campos requeridos completos
    // When: usuario hace click en "Generar con IA"
    // Then: se llama a POST /ai/generate-description con payload correcto
  });
});
```

```java
// Ejemplo Backend
@Test
public void testCreateJobPosting_WithValidData_ReturnsCreated() {
    // Given: JobPostingDTO v√°lido con todos los campos requeridos
    // When: POST /api/job-postings
    // Then: Status 201 Created + Location header + objeto creado en DB
}
```

### 3. Implementaci√≥n

Describe los archivos a crear/modificar y la l√≥gica principal.

### 4. Refactoring

¬øQu√© c√≥digo existente debe refactorizarse para soportar esta feature?

---

**Formato de Ticket TDD:**

**[TIPO-XXX]: T√≠tulo**

**Tests a Implementar:**
- [Lista de tests unitarios, integraci√≥n, E2E]

**Criterios de Aceptaci√≥n (Ejecutables):**
```typescript
// Pseudoc√≥digo de tests
```

**Implementaci√≥n:**
- Archivos a crear: [ ]
- Archivos a modificar: [ ]
- L√≥gica principal: [Descripci√≥n]

**Refactoring:**
- [Mejoras al c√≥digo existente]

**Estimaci√≥n:** X Story Points

---

Genera los tickets TDD para la User Story: **[INSERTAR US ELEGIDA]**
```

---

## PROMPT 3.3 - Tickets con Documentaci√≥n T√©cnica Incluida

```
Descomp√≥n la User Story en tickets t√©cnicos que incluyan **toda la documentaci√≥n t√©cnica necesaria** para que un desarrollador nuevo pueda implementarla sin ayuda.

Cada ticket debe incluir:

### 1. Contexto Arquitect√≥nico

**Servicios Involucrados:**
- [Nombre del servicio] - [Responsabilidad en este ticket]

**Flujo de Datos:**
```
User Action ‚Üí Frontend Component ‚Üí API Gateway ‚Üí Backend Service ‚Üí Database
                                                      ‚Üì
                                                   AI Service
```

**Diagrama de Secuencia (Mermaid):**
```mermaid
sequenceDiagram
    participant U as Usuario
    participant F as Frontend
    participant A as API Gateway
    participant R as Recruitment Service
    participant AI as AI Service
    participant DB as PostgreSQL

    U->>F: Completa formulario
    F->>A: POST /api/job-postings
    A->>R: Crear oferta
    R->>AI: Generar descripci√≥n
    AI-->>R: Descripci√≥n generada
    R->>DB: Insertar job_posting
    DB-->>R: ID creado
    R-->>A: 201 Created
    A-->>F: Respuesta
    F->>U: Muestra oferta creada
```

### 2. Especificaci√≥n T√©cnica

**API Contract:**
```typescript
// Request
POST /api/job-postings
{
  "title": "Senior Backend Developer",
  "department": "Engineering",
  "location": "Remote",
  "employment_type": "FULL_TIME",
  "salary_min": 60000,
  "salary_max": 90000,
  "salary_currency": "EUR"
}

// Response 201 Created
{
  "id": "uuid",
  "title": "Senior Backend Developer",
  "description": "[Generada por IA]",
  "status": "DRAFT",
  "created_at": "2025-11-15T10:30:00Z"
}
```

**Database Schema:**
```sql
CREATE TABLE job_postings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  title VARCHAR(200) NOT NULL,
  description TEXT,
  status VARCHAR(20) DEFAULT 'DRAFT',
  created_at TIMESTAMP DEFAULT NOW()
);
```

**Modelos de Datos:**
```java
@Entity
@Table(name = "job_postings")
public class JobPosting {
    @Id
    @GeneratedValue
    private UUID id;

    @Column(nullable = false, length = 200)
    private String title;

    @Column(columnDefinition = "TEXT")
    private String description;

    // ... getters/setters
}
```

### 3. Ejemplo de Implementaci√≥n

Pseudoc√≥digo o snippet de referencia:

```typescript
// Frontend - JobPostingForm.tsx
export const JobPostingForm = () => {
  const { mutate: createJob, isLoading } = useMutation({
    mutationFn: (data: JobFormData) =>
      api.post('/api/job-postings', data),
    onSuccess: (response) => {
      toast.success('Oferta creada exitosamente');
      navigate(`/jobs/${response.id}`);
    }
  });

  const onSubmit = async (data: JobFormData) => {
    // Si usuario pidi√≥ descripci√≥n IA, llamar primero a AI service
    if (data.generateWithAI) {
      const aiDescription = await generateDescription(data);
      data.description = aiDescription;
    }
    createJob(data);
  };

  return (/* JSX del formulario */);
};
```

### 4. Tests de Referencia

```java
@SpringBootTest
@AutoConfigureMockMvc
public class JobPostingControllerTest {

    @Test
    public void createJobPosting_ValidData_Returns201() throws Exception {
        String payload = """
            {
              "title": "Senior Backend Developer",
              "department": "Engineering",
              "location": "Remote"
            }
        """;

        mockMvc.perform(post("/api/job-postings")
                .contentType(MediaType.APPLICATION_JSON)
                .content(payload))
            .andExpect(status().isCreated())
            .andExpect(jsonPath("$.id").exists())
            .andExpect(jsonPath("$.title").value("Senior Backend Developer"));
    }
}
```

### 5. Checklist de Implementaci√≥n

- [ ] Crear migraci√≥n de BD (`V001__create_job_postings_table.sql`)
- [ ] Implementar entidad JPA `JobPosting.java`
- [ ] Crear DTOs: `JobPostingCreateDTO`, `JobPostingResponseDTO`
- [ ] Implementar `JobPostingController.createJobPosting()`
- [ ] Implementar `JobPostingService.create()`
- [ ] Agregar validaciones con Bean Validation (`@Valid`, `@NotNull`)
- [ ] Crear tests unitarios para Service
- [ ] Crear tests de integraci√≥n para Controller
- [ ] Documentar endpoint en OpenAPI/Swagger
- [ ] Actualizar Postman collection

---

**Formato de Ticket Completo:**

**[TIPO-XXX]: T√≠tulo del Ticket**

[Incluir todas las secciones arriba: Contexto Arquitect√≥nico, Especificaci√≥n T√©cnica, Ejemplo de Implementaci√≥n, Tests, Checklist]

**Estimaci√≥n:** X Story Points
**Asignado a:** [Rol]
**Prioridad:** [Alta/Media/Baja]

---

Genera ahora los tickets t√©cnicos completos con documentaci√≥n para: **[INSERTAR US ELEGIDA]**
```

---

# PARTE 4: Estimaci√≥n de Esfuerzo

## PROMPT 4.1 - Estimaci√≥n con Planning Poker (Fibonacci)

```
Ahora que tenemos los tickets t√©cnicos de la User Story descompuesta, vamos a estimarlos usando **Planning Poker con escala Fibonacci**.

## Contexto del Equipo

**Composici√≥n:**
- 2 Frontend Developers (React)
- 2 Backend Developers (Java Spring Boot)
- 1 ML Engineer (Python)
- 1 QA Engineer

**Definici√≥n de Story Points (Fibonacci):**

| Points | Descripci√≥n | Tiempo Aprox. | Ejemplo |
|--------|-------------|---------------|---------|
| **1** | Trivial, sin incertidumbre | 1-2 horas | Cambiar texto de un bot√≥n, ajustar estilo CSS |
| **2** | Simple, bien entendido | Medio d√≠a | Agregar validaci√≥n simple, crear endpoint CRUD b√°sico |
| **3** | Moderado, clara implementaci√≥n | 1 d√≠a | Formulario con validaciones, endpoint con l√≥gica de negocio |
| **5** | Complejo, requiere investigaci√≥n | 2-3 d√≠as | Integraci√≥n con API externa, componente con estado complejo |
| **8** | Muy complejo, m√∫ltiples partes | 4-5 d√≠as (1 semana) | Feature completa con frontend + backend + tests |
| **13** | √âpico peque√±o, alta incertidumbre | 2 semanas | M√≥dulo completo con m√∫ltiples integraciones |
| **21** | Demasiado grande, debe dividirse | 3+ semanas | ‚ö†Ô∏è Dividir en tickets m√°s peque√±os |

## Formato de Estimaci√≥n

Para cada ticket generado, proporciona:

### Tabla de Estimaci√≥n

| Ticket ID | T√≠tulo | Complejidad T√©cnica | Incertidumbre | Esfuerzo Frontend | Esfuerzo Backend | Esfuerzo IA | Esfuerzo QA | **Estimaci√≥n Final** | Justificaci√≥n |
|-----------|--------|---------------------|---------------|-------------------|------------------|-------------|-------------|----------------------|---------------|
| FRONT-001 | Formulario Creaci√≥n Oferta | Media | Baja | 5 | - | - | 2 | **5 SP** | Formulario est√°ndar con validaciones conocidas, integraci√≥n API directa |
| BACK-001 | Endpoint POST /job-postings | Media | Baja | - | 3 | - | 1 | **3 SP** | CRUD est√°ndar con validaciones, sin l√≥gica compleja |
| AI-001 | Integraci√≥n LLM Generaci√≥n Descripci√≥n | Alta | Alta | - | 2 | 8 | 2 | **8 SP** | Primera integraci√≥n con LLM, requiere prompt engineering, manejo de rate limits |
| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |

### Resumen por User Story

**User Story:** US-001 - Crear Oferta con Asistencia de IA

**Tickets:**
- FRONT-001: 5 SP
- FRONT-002: 3 SP
- BACK-001: 3 SP
- BACK-002: 5 SP
- AI-001: 8 SP
- DATA-001: 2 SP
- TEST-001: 3 SP
- DEVOPS-001: 2 SP

**Total US-001:** 31 Story Points

**Estimaci√≥n de Timeline:**
- Con 6 developers (asumiendo 8 SP por dev por semana)
- Capacidad semanal: 48 SP
- **Duraci√≥n estimada:** 4-5 d√≠as (~0.75 sprints)

### Factores de Riesgo

Identifica tickets con:
- üî¥ **Alta incertidumbre:** AI-001 (primera integraci√≥n con LLM)
- üü° **Dependencias cr√≠ticas:** BACK-001 debe completarse antes que FRONT-001
- üü¢ **Quick wins:** DATA-001 (migraci√≥n simple)

### Recomendaciones

1. **Spike t√©cnico:** Invertir 1 d√≠a en investigar integraci√≥n con LLM antes de estimar definitivamente AI-001
2. **Pair programming:** AI-001 requiere colaboraci√≥n Backend + ML Engineer
3. **Paralelizaci√≥n:** FRONT-001 y BACK-001 pueden desarrollarse en paralelo con API contract mock

---

Genera ahora la estimaci√≥n completa con Planning Poker para todos los tickets de: **[INSERTAR US ELEGIDA]**
```

---

## PROMPT 4.2 - Estimaci√≥n con Tallas de Camiseta + Conversi√≥n a Horas

```
Estima los tickets t√©cnicos usando **Tallas de Camiseta (T-Shirt Sizes)** y luego convi√©rtelos a **horas de esfuerzo** para planificaci√≥n de sprint.

## Escala de Tallas

| Talla | Descripci√≥n | Horas Aprox. | Story Points Equiv. |
|-------|-------------|--------------|---------------------|
| **XS** | Cambio trivial | 1-2 horas | 1 SP |
| **S** | Tarea simple | 3-4 horas | 2 SP |
| **M** | Tarea est√°ndar | 1 d√≠a (8 horas) | 3-5 SP |
| **L** | Tarea compleja | 2-3 d√≠as (16-24 horas) | 8 SP |
| **XL** | Muy complejo | 4-5 d√≠as (32-40 horas) | 13 SP |
| **XXL** | ‚ö†Ô∏è Dividir | 1+ semana | 21+ SP |

## Formato de Estimaci√≥n

### Paso 1: Clasificaci√≥n por Tallas

| Ticket ID | T√≠tulo | Talla | Raz√≥n de la Talla |
|-----------|--------|-------|-------------------|
| FRONT-001 | Formulario Creaci√≥n Oferta | M | Formulario mediano con 7 campos, validaciones est√°ndar, integraci√≥n API |
| AI-001 | Integraci√≥n LLM | L | Primera integraci√≥n con servicio externo, requiere manejo de errores robusto, prompt engineering |
| DATA-001 | Migraci√≥n BD job_postings | XS | Migraci√≥n simple con script est√°ndar |
| ... | ... | ... | ... |

### Paso 2: Conversi√≥n a Horas

| Ticket ID | Talla | Horas Desarrollo | Horas Testing | Horas Review/QA | **Total Horas** | Asignado a |
|-----------|-------|------------------|---------------|-----------------|-----------------|------------|
| FRONT-001 | M | 6 | 2 | 1 | **9h** | Frontend Dev |
| AI-001 | L | 16 | 4 | 2 | **22h** | ML Engineer + Backend Dev |
| DATA-001 | XS | 1 | 0.5 | 0.5 | **2h** | Backend Dev |
| ... | ... | ... | ... | ... | ... | ... |

### Paso 3: Planificaci√≥n de Sprint

**Sprint 1 - Semana 1:**
- Capacidad: 6 devs √ó 30 horas productivas = 180 horas disponibles

**Distribuci√≥n:**
- Frontend: 2 devs √ó 30h = 60h
  - FRONT-001: 9h
  - FRONT-002: 6h
  - FRONT-003: 12h
  - ...

- Backend: 2 devs √ó 30h = 60h
  - BACK-001: 8h
  - BACK-002: 14h
  - ...

- ML: 1 dev √ó 30h = 30h
  - AI-001: 22h
  - AI-002: 8h

- QA: 1 QA √ó 30h = 30h
  - Testing de todos los tickets

**Total Planificado:** XXX horas de YYY disponibles ‚Üí ZZ% utilizaci√≥n

### Paso 4: Identificar Cuellos de Botella

```
Diagrama de dependencias:
DATA-001 (2h) ‚Üí BACK-001 (8h) ‚Üí FRONT-001 (9h)
                     ‚Üì
                  AI-001 (22h) ‚ö†Ô∏è Critical path
```

**Riesgos:**
- üî¥ AI-001 est√° en la ruta cr√≠tica y es L (complejo)
- üü° Si AI-001 se retrasa, bloquea FRONT-001

**Mitigaci√≥n:**
- Empezar AI-001 en d√≠a 1 con pair programming
- Crear mock de AI Service para desbloquear FRONT-001

---

Genera ahora la estimaci√≥n completa por tallas y horas para: **[INSERTAR US ELEGIDA]**
```

---

## PROMPT 4.3 - Estimaci√≥n con An√°lisis de Riesgos y Contingencia

```
Estima los tickets t√©cnicos incluyendo un **an√°lisis de riesgos** y **factor de contingencia** para planificaci√≥n realista.

## Metodolog√≠a

Para cada ticket, eval√∫a:

### 1. Estimaci√≥n Base

| Ticket | Estimaci√≥n Optimista (Best Case) | Estimaci√≥n Probable (Most Likely) | Estimaci√≥n Pesimista (Worst Case) |
|--------|----------------------------------|-----------------------------------|-----------------------------------|
| FRONT-001 | 3 SP | 5 SP | 8 SP |
| AI-001 | 5 SP | 8 SP | 13 SP |
| ... | ... | ... | ... |

### 2. F√≥rmula PERT (Program Evaluation and Review Technique)

```
Estimaci√≥n PERT = (Optimista + 4√óProbable + Pesimista) / 6
```

**Ejemplo:**
- AI-001: (5 + 4√ó8 + 13) / 6 = **8.3 SP** ‚Üí Redondear a **8 SP**

### 3. Factores de Riesgo

| Ticket | Riesgo T√©cnico | Riesgo de Dependencias | Riesgo de Requisitos | Riesgo Total | Factor Contingencia |
|--------|----------------|------------------------|----------------------|--------------|---------------------|
| FRONT-001 | Bajo (1) | Medio (2) | Bajo (1) | 4/15 | 10% |
| AI-001 | Alto (3) | Alto (3) | Medio (2) | 8/15 | 30% |

**Escalas:**
- Bajo = 1, Medio = 2, Alto = 3
- Factor contingencia = (Riesgo Total / 15) √ó 50%

### 4. Estimaci√≥n Final con Contingencia

| Ticket | Estimaci√≥n PERT | Factor Contingencia | **Estimaci√≥n Final Ajustada** |
|--------|-----------------|---------------------|-------------------------------|
| FRONT-001 | 5 SP | 10% | 5 √ó 1.1 = **5.5 SP** ‚Üí 5 SP |
| AI-001 | 8 SP | 30% | 8 √ó 1.3 = **10.4 SP** ‚Üí 10 SP |

### 5. Resumen por User Story

**US-001: Crear Oferta con IA**

| Categor√≠a | Suma Estimaciones Base | Suma con Contingencia | Diferencia |
|-----------|------------------------|----------------------|------------|
| Frontend | 15 SP | 17 SP | +13% |
| Backend | 12 SP | 14 SP | +17% |
| IA | 8 SP | 10 SP | +25% |
| Testing | 5 SP | 6 SP | +20% |
| **Total** | **40 SP** | **47 SP** | **+17.5%** |

**Interpretaci√≥n:**
- Estimaci√≥n optimista: 40 SP (2 semanas con equipo completo)
- Estimaci√≥n realista con contingencia: 47 SP (2.3 semanas)
- **Recomendaci√≥n:** Planificar 2.5 semanas para dar margen

### 6. Estrategia de Mitigaci√≥n de Riesgos

**Riesgos Identificados:**

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|-------------|---------|------------|
| Integraci√≥n LLM falla o es lenta | Alta | Alto | Implementar timeout + fallback manual, spike t√©cnico previo |
| Cambios en requisitos de formulario | Media | Medio | Prototipar UI con stakeholders antes de desarrollar |
| Bloqueo por dependencias externas | Baja | Alto | Usar mocks y contract testing |

**Tickets m√°s riesgosos (priorizar atenci√≥n):**
1. üî¥ AI-001 (10 SP ajustados, 30% contingencia)
2. üü° BACK-002 (6 SP ajustados, 20% contingencia)

---

Genera ahora el an√°lisis completo de estimaci√≥n con riesgos para: **[INSERTAR US ELEGIDA]**
```

---

# PARTE 5: Conclusiones y Recomendaciones

## Metodolog√≠a Recomendada para el Proyecto LTI ATS

### Para Generaci√≥n de User Stories
‚úÖ **Usar PROMPT 1.1** (Enfoque Completo) por:
- Genera documentaci√≥n completa y consistente de una vez
- Incluye todos los elementos necesarios (criterios, tareas, relaciones)
- Facilita revisi√≥n en equipo en una sola sesi√≥n

### Para Creaci√≥n del Backlog
‚úÖ **Usar PROMPT 2.1** (MoSCoW) como base, complementar con **PROMPT 2.4** (Story Mapping) para:
- MoSCoW: Priorizaci√≥n r√°pida alineada con el PRD
- Story Mapping: Visualizar roadmap y walking skeleton del MVP

### Para Tickets de Trabajo
‚úÖ **Usar PROMPT 3.1** (Descomposici√≥n T√©cnica Completa) por:
- Balance √≥ptimo entre detalle y pragmatismo
- Incluye arquitectura, dependencias, DoD
- Formato Jira-ready

### Para Estimaci√≥n
‚úÖ **Usar PROMPT 4.1** (Planning Poker Fibonacci) + **PROMPT 4.3** (An√°lisis de Riesgos) por:
- Planning Poker: Facilita consenso en el equipo
- An√°lisis de Riesgos: Agrega realismo a estimaciones cr√≠ticas (tickets con IA)

---

## Workflow Recomendado

```
1. Ejecutar PROMPT INICIAL (contexto)
   ‚Üì
2. Ejecutar PROMPT 1.1 ‚Üí Generar 8-10 User Stories
   ‚Üì
3. Ejecutar PROMPT 2.1 ‚Üí Crear Backlog con MoSCoW
   ‚Üì
4. (Opcional) Ejecutar PROMPT 2.4 ‚Üí Crear Story Map visual
   ‚Üì
5. Elegir Top 2-3 US del backlog
   ‚Üì
6. Para cada US: Ejecutar PROMPT 3.1 ‚Üí Generar tickets t√©cnicos
   ‚Üì
7. Ejecutar PROMPT 4.1 ‚Üí Estimar tickets con Planning Poker
   ‚Üì
8. Para tickets de alta complejidad: Ejecutar PROMPT 4.3 ‚Üí An√°lisis de riesgos
   ‚Üì
9. Revisar con el equipo en Planning Meeting
   ‚Üì
10. Ajustar y commitear al sprint!
```

---

## Checklist de Validaci√≥n Final

Antes de dar por terminada la documentaci√≥n, verifica:

### User Stories
- [ ] Cada US sigue formato est√°ndar (Como/Quiero/Para que)
- [ ] M√≠nimo 3 criterios de aceptaci√≥n por US en formato Dado-Cuando-Entonces
- [ ] Incluye actor principal claramente identificado
- [ ] Tareas t√©cnicas son espec√≠ficas y accionables
- [ ] Hay al menos 1 US desde perspectiva del Candidato

### Backlog
- [ ] Todas las US est√°n priorizadas con metodolog√≠a clara (MoSCoW/RICE/Kano)
- [ ] Hay justificaci√≥n escrita de la priorizaci√≥n
- [ ] Se identifican dependencias entre US
- [ ] Se propone distribuci√≥n en sprints
- [ ] Walking skeleton del MVP est√° identificado

### Tickets de Trabajo
- [ ] Cada ticket es at√≥mico (completable en 0.5-2 d√≠as)
- [ ] Incluye criterios de aceptaci√≥n t√©cnicos
- [ ] Tiene Definition of Done clara
- [ ] Especifica dependencias de otros tickets
- [ ] Asigna especialidad requerida (Frontend/Backend/IA/QA)

### Estimaciones
- [ ] Todos los tickets tienen estimaci√≥n
- [ ] Se justifica la estimaci√≥n de tickets >5 SP
- [ ] Se identifican riesgos en tickets complejos
- [ ] Suma total de US no excede capacidad del sprint
- [ ] Hay factor de contingencia para tickets de IA

---

**√öltima Actualizaci√≥n:** 2025-12-02
**Versi√≥n del Documento:** 2.0
**Proyecto:** LTI ATS - Applicant Tracking System
